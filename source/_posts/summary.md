# Central Idea  
  
# roadmap  
  
## DQN  
  
### scale up  
  
* fix ARC problem  
* evaluation vs mdp  
    * https://github.com/yujianyuanhaha/blog/blob/master/source/_posts/research/dqn-dsa.md  
    *  https://docs.google.com/presentation/d/1p9AhgvpaWANCys856DfBQLIaou4lAqHhhfXEB3e1zhA/edit#slide=id.p  
* evaluation various dqn  
  
### policy-based RL  
  
* fix learn interminttent  
    * correct understanding of ‘eposide’  
* vs dqn  
* proof learn stochastic  
  
### pomdp  
  
* pomcp  
* DRQN  
    * add in Yue  
  
### stochastic  
  
* dynamic reward setting  
* vs ESN echo state network  
    * in publication, claim to learn stochastic  
    * open source  
    * blog github.com/yujianyuanhaha/blog/blob/master/source/_posts/tutorial/esn.md  
* 2-state Markov Chain  
    * poisson  
  
### realistic mode  
  
* interference  
* noise  
* dynamic network  
    * shorten the converge cast  
* hidden/ expose nodes  
  
### refined  
  
* converge time  
* new metric, espeical for WAIT  
* export cvs under folder with time & type-in name  
* export npy  
* support dpg, ac  
* python 3.0 support  
  
## Ersin Radar DQN  
  
### evaluation on ARC dqn vs mdp  
  
### various dqn e.g. duel dqn  
  
### ~ fair metric like PER  
  
### online training  
  
### hint for DQN-DSA  
  
* occupy multiple channels  
* offline training for fast convergecasr  
* SINR model  
  
## GNU Radio  
  
